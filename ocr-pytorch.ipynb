{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d06312f",
   "metadata": {
    "papermill": {
     "duration": 0.003213,
     "end_time": "2024-04-15T01:55:26.640155",
     "exception": false,
     "start_time": "2024-04-15T01:55:26.636942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TONG HOP CODE FOR TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "311d9a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T01:55:26.647756Z",
     "iopub.status.busy": "2024-04-15T01:55:26.646860Z",
     "iopub.status.idle": "2024-04-15T01:55:41.712560Z",
     "shell.execute_reply": "2024-04-15T01:55:41.711507Z"
    },
    "papermill": {
     "duration": 15.072035,
     "end_time": "2024-04-15T01:55:41.714979",
     "exception": false,
     "start_time": "2024-04-15T01:55:26.642944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\r\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a7a06c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T01:55:41.722632Z",
     "iopub.status.busy": "2024-04-15T01:55:41.722303Z",
     "iopub.status.idle": "2024-04-15T01:55:42.141322Z",
     "shell.execute_reply": "2024-04-15T01:55:42.140525Z"
    },
    "papermill": {
     "duration": 0.425518,
     "end_time": "2024-04-15T01:55:42.143681",
     "exception": false,
     "start_time": "2024-04-15T01:55:41.718163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da99dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T01:55:42.151392Z",
     "iopub.status.busy": "2024-04-15T01:55:42.150839Z",
     "iopub.status.idle": "2024-04-15T01:56:36.589631Z",
     "shell.execute_reply": "2024-04-15T01:56:36.588639Z"
    },
    "papermill": {
     "duration": 54.44777,
     "end_time": "2024-04-15T01:56:36.594584",
     "exception": false,
     "start_time": "2024-04-15T01:55:42.146814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '3', '4', '5', '6', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'W', 'X', 'Y', 'Z']\n",
      "Setup done---\n",
      "torch.Size([6588, 3, 64, 64])\n",
      "torch.Size([6588])\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#from torchsummary import summary\n",
    "#define model for training as class\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1) \n",
    "        # (channels, features matrix dimension, kernel size, padding)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 128)  # Calculate input size for fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 30)  # Adjust output size to match your number of classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(-1, 128 * 8 * 8)  # Flatten the output from the convolutional layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)  # Apply softmax for multi-class classification\n",
    "        return x\n",
    "\n",
    "#function for sorting the classes: \n",
    "def custom_sort(classes):\n",
    "    numbers = []\n",
    "    characters = []\n",
    "    for item in classes:\n",
    "        if item.isdigit():\n",
    "            numbers.append(str(item))  # Convert to int for numerical sorting\n",
    "        else:\n",
    "            characters.append(item)\n",
    "    numbers.sort()\n",
    "    characters.sort()\n",
    "    return numbers + characters\n",
    "#LOAD DATA AND ITS LABEL INTO 2 TENSOR\n",
    "train_path = '/kaggle/input/new-ocr-dot-matrix/trainingV2/train'\n",
    "#prepare data \n",
    "classes = os.listdir(train_path)\n",
    "classes = custom_sort(classes) \n",
    "#read all folder to store label into an array\n",
    "print(classes)\n",
    "imgs_tensor = []\n",
    "labels_tensor=[]\n",
    "for item in classes:\n",
    "    #print(os.path.join(path, folder))\n",
    "    img_folder = os.path.join(train_path, item)        \n",
    "    for image in os.listdir(img_folder):\n",
    "        #input image\n",
    "        image_path = os.path.join(img_folder, image)\n",
    "        #|img = cv2.imread(image_path,cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        img = img/255     \n",
    "        #img = transforms.ToTenSor(img)  \n",
    "        img = img[np.newaxis, ...]\n",
    "        #img = img[np.newaxis, ...]\n",
    "        img_tensor = torch.from_numpy(img)     \n",
    "        imgs_tensor.append(img_tensor)\n",
    "\n",
    "    #output label with numpy \n",
    "        label = np.array(classes.index(item))\n",
    "        label = label[np.newaxis]\n",
    "        label_tensor = torch.from_numpy(label)   \n",
    "        labels_tensor.append(label_tensor)\n",
    "    #output\n",
    "        #index = np.array(classes.index(item))\n",
    "        #labels_tensor[i][index]=1\n",
    "X = torch.cat(imgs_tensor, dim=0)\n",
    "#dim = 0, concatenate by row\n",
    "#dim = 1, concatenate by column\n",
    "Y = torch.cat(labels_tensor, dim=0)\n",
    "X_sh, y_sh = shuffle(X, Y, random_state=42)\n",
    "#load 2 tensor to dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "#Call model \n",
    "model = CNNModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=0.0001)\n",
    "\n",
    "print(\"Setup done---\")\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "327182ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-15T01:56:36.601887Z",
     "iopub.status.busy": "2024-04-15T01:56:36.601483Z",
     "iopub.status.idle": "2024-04-15T02:08:05.849757Z",
     "shell.execute_reply": "2024-04-15T02:08:05.848712Z"
    },
    "papermill": {
     "duration": 689.257938,
     "end_time": "2024-04-15T02:08:05.855562",
     "exception": false,
     "start_time": "2024-04-15T01:56:36.597624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy = 23.74%\n",
      "Epoch 2: Accuracy = 46.07%\n",
      "Epoch 3: Accuracy = 52.26%\n",
      "Epoch 4: Accuracy = 56.06%\n",
      "Epoch 5: Accuracy = 57.59%\n",
      "Epoch 6: Accuracy = 65.73%\n",
      "Epoch 7: Accuracy = 74.91%\n",
      "Epoch 8: Accuracy = 78.40%\n",
      "Epoch 9: Accuracy = 79.40%\n",
      "Epoch 10: Accuracy = 84.47%\n",
      "Epoch 11: Accuracy = 85.05%\n",
      "Epoch 12: Accuracy = 85.05%\n",
      "Epoch 13: Accuracy = 85.05%\n",
      "Epoch 14: Accuracy = 86.37%\n",
      "Epoch 15: Accuracy = 89.01%\n",
      "Epoch 16: Accuracy = 91.62%\n",
      "Epoch 17: Accuracy = 91.62%\n",
      "Epoch 18: Accuracy = 91.62%\n",
      "Epoch 19: Accuracy = 91.62%\n",
      "Epoch 20: Accuracy = 91.62%\n",
      "Training Done------\n"
     ]
    }
   ],
   "source": [
    "#Training model on pytorch\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    j=0\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        # Forward pass, track output and targets\n",
    "        outputs = model(data)\n",
    "        #output dimension is (minibatch_size, number of classes)\n",
    "        value, predicted = torch.max(outputs, 1)\n",
    "        total_correct += (predicted == target).sum().item()\n",
    "        total_samples += target.size(0)\n",
    "\n",
    "        # Backward pass and update parameters (unchanged)\n",
    "        loss = criterion(outputs, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    print(f'Epoch {epoch+1}: Accuracy = {accuracy:.2f}%')\n",
    "model_path = '/kaggle/working/model.pt'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Training Done------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93eb08b",
   "metadata": {
    "papermill": {
     "duration": 0.004439,
     "end_time": "2024-04-15T02:08:05.864685",
     "exception": false,
     "start_time": "2024-04-15T02:08:05.860246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4510195,
     "sourceId": 7721165,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4741348,
     "sourceId": 8041897,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 766.262159,
   "end_time": "2024-04-15T02:08:09.138210",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-15T01:55:22.876051",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
